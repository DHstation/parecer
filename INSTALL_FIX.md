# ğŸ”§ CorreÃ§Ã£o da InstalaÃ§Ã£o

## Problema Resolvido

O erro `ERR_REQUIRE_ESM` com `@xenova/transformers` foi resolvido.

**MudanÃ§as realizadas:**

1. âœ… Removidas dependÃªncias pesadas:
   - `@xenova/transformers`
   - `@langchain/*`
   - `faiss-node`

2. âœ… Implementado sistema RAG simplificado usando **TF-IDF**
   - Mais leve e rÃ¡pido
   - NÃ£o requer GPU
   - Funciona offline
   - Boa performance para busca semÃ¢ntica

## ğŸš€ Como Proceder

### 1. Remover node_modules antigo e reinstalar

```bash
cd ~/parecer/backend

# Remover instalaÃ§Ã£o antiga
rm -rf node_modules package-lock.json

# Reinstalar com dependÃªncias atualizadas
npm install
```

### 2. Iniciar o backend

```bash
npm run dev
```

Agora deve funcionar sem erros! âœ…

## ğŸ“ O que mudou no RAG?

### Antes (com erro):
- Usava `@xenova/transformers` para embeddings neurais
- Pesado (~500MB)
- DependÃªncia ESM problemÃ¡tica

### Agora (funcionando):
- Usa **TF-IDF (Term Frequency-Inverse Document Frequency)**
- Leve e rÃ¡pido
- Sem dependÃªncias externas pesadas
- Funciona muito bem para busca de texto

### Como funciona o TF-IDF?

1. **TokenizaÃ§Ã£o**: Divide o texto em palavras
2. **FrequÃªncia**: Calcula frequÃªncia de cada termo
3. **NormalizaÃ§Ã£o**: Cria vetor de features
4. **Similaridade**: Compara vetores usando cosseno

**Exemplo:**
```
Texto 1: "contrato de compra e venda"
Texto 2: "contrato de locaÃ§Ã£o"

Palavras em comum: "contrato", "de"
Similaridade: ~0.6 (60%)
```

## ğŸ¯ Performance

### TF-IDF vs Embeddings Neurais

| Aspecto | TF-IDF | Embeddings Neurais |
|---------|--------|-------------------|
| Velocidade | âš¡ Muito rÃ¡pido | ğŸŒ Lento |
| MemÃ³ria | ğŸ’¾ Baixa (~10MB) | ğŸ—„ï¸ Alta (~500MB+) |
| PrecisÃ£o | âœ… Boa para texto | ğŸ¯ Excelente |
| Setup | âœ… Zero config | âš™ï¸ Requer GPU/API |

Para documentos jurÃ­dicos com vocabulÃ¡rio especÃ­fico, **TF-IDF Ã© suficiente e eficiente**!

## ğŸ”® Upgrade Futuro (Opcional)

Se quiser embeddings mais sofisticados no futuro, pode usar APIs externas:

### OpÃ§Ã£o A: OpenAI Embeddings

```javascript
// Em ragService.js
async generateEmbedding(text) {
  if (process.env.OPENAI_API_KEY) {
    const response = await axios.post(
      'https://api.openai.com/v1/embeddings',
      {
        model: 'text-embedding-3-small',
        input: text
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
        }
      }
    );
    return response.data.data[0].embedding;
  }

  // Fallback para TF-IDF
  return this.generateSimpleEmbedding(text);
}
```

### OpÃ§Ã£o B: Cohere Embeddings

```bash
npm install cohere-ai
```

```javascript
const { CohereClient } = require('cohere-ai');

const cohere = new CohereClient({
  token: process.env.COHERE_API_KEY,
});

const response = await cohere.embed({
  texts: [text],
  model: 'embed-multilingual-v3.0',
});
```

### OpÃ§Ã£o C: Hugging Face API

```javascript
const response = await axios.post(
  'https://api-inference.huggingface.co/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
  { inputs: text },
  {
    headers: {
      'Authorization': `Bearer ${process.env.HUGGING_FACE_TOKEN}`
    }
  }
);
```

## âœ… Checklist PÃ³s-CorreÃ§Ã£o

- [ ] `rm -rf backend/node_modules backend/package-lock.json`
- [ ] `cd backend && npm install`
- [ ] Verificar que nÃ£o hÃ¡ erros ESM
- [ ] `npm run dev` - deve iniciar sem erros
- [ ] Testar upload de documento
- [ ] Testar busca semÃ¢ntica

## ğŸ†˜ Se ainda der erro

```bash
# Verificar versÃ£o do Node
node --version  # Deve ser 18+

# Limpar cache do npm
npm cache clean --force

# Reinstalar globalmente nodemon
npm install -g nodemon

# Tentar novamente
cd ~/parecer/backend
rm -rf node_modules package-lock.json
npm install
npm run dev
```

## ğŸ“ Logs Ãšteis

Se precisar debugar:

```javascript
// Em ragService.js, adicione no construtor:
console.log('RAG Service initialized');
console.log('Vector store size:', this.vectorStore.size);
```

---

**Problema resolvido! Sistema mais leve e funcional! ğŸ‰**
